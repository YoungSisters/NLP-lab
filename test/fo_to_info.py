# -*- coding: utf-8 -*-
"""fo_to_info.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dXwgfn0qIQWLHpRXk1wPt583LBDlYnVc
"""

import numpy as np
from keras.models import Model
from keras.layers import Input, LSTM, Dense, Embedding

# 50k sentence pairs
with open("/content/drive/MyDrive/speaKing/Family_Relationships_informal.txt", "r") as f:
    informal_sentences = f.readlines()
with open("/content/drive/MyDrive/speaKing/Family_Relationships_formal.txt", "r") as f:
    formal_sentences = f.readlines()

# Preprocess the data by tokenizing and encoding the sentences
input_texts = []
target_texts = []
input_vocab = set()
target_vocab = set()
for i in range(len(formal_sentences)):
    input_text = formal_sentences[i].strip().lower()
    target_text = informal_sentences[i].strip().lower()
    input_texts.append(input_text)
    target_texts.append(target_text)
    for char in input_text:
        if char not in input_vocab:
            input_vocab.add(char)
    for char in target_text:
        if char not in target_vocab:
            target_vocab.add(char)
input_vocab = sorted(list(input_vocab))
target_vocab = sorted(list(target_vocab))
num_encoder_tokens = len(input_vocab)
num_decoder_tokens = len(target_vocab)
max_encoder_seq_length = max([len(txt) for txt in input_texts])
max_decoder_seq_length = max([len(txt) for txt in target_texts])
input_token_index = dict([(char, i) for i, char in enumerate(input_vocab)])
target_token_index = dict([(char, i) for i, char in enumerate(target_vocab)])
encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype="float32")
decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype="float32")
decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype="float32")
for i in range(len(input_texts)):
    for j, char in enumerate(input_texts[i]):
        encoder_input_data[i, j, input_token_index[char]] = 1.0
    for j, char in enumerate(target_texts[i]):
        decoder_input_data[i, j, target_token_index[char]] = 1.0
        if j > 0:
            decoder_target_data[i, j-1, target_token_index[char]] = 1.0

model.compile(optimizer="rmsprop", loss="categorical_crossentropy")
model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=100, validation_split=0.2)

model.save("formal_to_informal.h5") #path/to/location